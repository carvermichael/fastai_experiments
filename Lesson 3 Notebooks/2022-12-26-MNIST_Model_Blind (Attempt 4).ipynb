{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf8f751-48a7-411e-a432-a8b689598887",
   "metadata": {},
   "source": [
    "# MNIST Model From \"Scratch\" -- Attempt 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbbec28-ec69-4f83-bfd8-8c495b97add0",
   "metadata": {},
   "source": [
    "Goal: To reproduce SGD \"from scratch\", starting from the point in the book where the data has been loaded.\n",
    "\n",
    "This means creating the following:\n",
    "- parameter initialization\n",
    "- linear net function\n",
    "- loss function\n",
    "- metric function (accuracy)\n",
    "- step function\n",
    "- function to train a single epoch\n",
    "\n",
    "I'm doing it this way, because it will be a more efficient way to learn this piece of things. I've gotten caught up doing the data ingestion piece before."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d986f67-a3ad-4ca9-8f69-7a3269076795",
   "metadata": {},
   "source": [
    "### Copied Piece \n",
    "Mostly my own way, but also checking shapes with the reference along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef869b6-bf8d-4459-bfae-474b1036a354",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.data.all import untar_data, URLs\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "from numpy import *\n",
    "\n",
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path\n",
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "seven_tensors = [torch.as_tensor(array(Image.open(o))) for o in sevens]\n",
    "three_tensors = [torch.as_tensor(array(Image.open(o))) for o in threes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a180c5f3-353c-44c3-9b92-64416149ea4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([6265, 28, 28]), torch.Size([6131, 28, 28]))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_sevens = torch.stack(seven_tensors).float() / 255\n",
    "stacked_threes = torch.stack(three_tensors).float() / 255\n",
    "stacked_sevens.shape, stacked_threes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62e39077-d64f-498a-bbb3-d9bfb6f25e0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([12396, 784])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = torch.cat([stacked_threes, stacked_sevens]).view(-1, 28*28)\n",
    "train_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19cda1da-9b2b-4f58-95f2-188b16625743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 784]), torch.Size([12396, 1]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This might be where I messed up last time...\n",
    "\n",
    "train_y = torch.as_tensor(\n",
    "    array([1]*len(threes) + [0]*len(sevens))\n",
    ").unsqueeze(1)\n",
    "train_x.shape,train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc39ccec-140c-4bc9-b9c1-3c9787c58a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784]), tensor([1]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dset = list(zip(train_x,train_y))\n",
    "x,y = dset[0]\n",
    "x.shape,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c534930-1527-405a-9541-5c4950a87cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1010, 28, 28]), torch.Size([1028, 28, 28]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_3_tens = torch.stack([torch.as_tensor(array(Image.open(o))) \n",
    "                            for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "valid_7_tens = torch.stack([torch.as_tensor(array(Image.open(o))) \n",
    "                            for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "valid_3_tens.shape,valid_7_tens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dd00ac71-0b11-44c0-a31a-965a71af1ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = torch.as_tensor(array([1]*len(valid_3_tens) + [0]*len(valid_7_tens))).unsqueeze(1)\n",
    "valid_dset = list(zip(valid_x,valid_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a017c129-1496-421a-b409-4deab39f2472",
   "metadata": {},
   "source": [
    "### Starting Without Reference Here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b39a60e-8ebc-49dc-9d71-8c74b8c47366",
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_init(shape): return torch.randn(shape).requires_grad_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "dcce1d9b-003f-43f4-af2b-df85ba3b901d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 1]), torch.Size([1]))"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = param_init((28*28, 1))\n",
    "bias = param_init(1)\n",
    "weights.shape, bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "56615233-352d-4ba4-9198-0bbc7fc4643b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.3417],\n",
       "         [-0.5647],\n",
       "         [ 0.2852],\n",
       "         [ 0.7432],\n",
       "         [ 0.6148]], grad_fn=<SliceBackward0>),\n",
       " tensor([0.0722], requires_grad=True))"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights[0:5], bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ae2556b2-b010-450e-8c2a-8a24ad3a4e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_loss(preds, tars): return torch.where(tars == 1, 1-preds, preds).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "707cd526-5a29-4d97-86c2-a5de1c965ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, tars): return ((preds > 0.5) == tars).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a825a20d-d2ad-41ea-964b-6f6d8c38f694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6666666865348816, 0.3333333432674408)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_preds = torch.as_tensor([0.4, 0.7, 0.1])\n",
    "test_tars = torch.as_tensor([0, 0, 1])\n",
    "test_loss = mnist_loss(test_preds, test_tars)\n",
    "test_acc = accuracy(test_preds, test_tars)\n",
    "test_loss.item(), test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "02481cac-4600-44d9-b55c-188f2b534f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(lr=1):\n",
    "    for p in (weights, bias):\n",
    "        p.data -= p.grad * lr\n",
    "        p.grad = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "812c0455-3a33-4635-88a6-24f455a64f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linNet(xb): return xb@weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e6f04188-c599-435b-acf3-6ba3d234d61c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([256, 784]), torch.Size([256, 1]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from fastai.data.load import DataLoader\n",
    "\n",
    "dset = DataLoader(dset, bs=256)\n",
    "dset.one_batch()[0].shape, dset.one_batch()[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "91e9b719-8ef2-416b-94f1-7d28679861c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_epoch():\n",
    "    for xb, yb in dset:\n",
    "        preds = linNet(xb).sigmoid_()\n",
    "        loss = mnist_loss(preds, yb)\n",
    "        # print(f\"preds: {preds[10:12]}, yb: {yb[10:12]}, loss: {loss}\")\n",
    "        loss.backward()\n",
    "        step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "27884eeb-777c-40f1-8799-c61f5363f389",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy():\n",
    "    with torch.no_grad():\n",
    "        acc = torch.as_tensor([accuracy(linNet(xb).sigmoid_(), yb) for xb, yb in valid_dset]).mean()\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0b2f63c9-f48f-493b-a735-586a66c2c981",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9637)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7b5f9b0b-40fa-4469-b4e6-2bf904ed7632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9642)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_epoch()\n",
    "get_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "545f633a-2ba1-4f3e-81e1-577156a6250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_n_epochs(n):\n",
    "    for i in range(n):\n",
    "        one_epoch()\n",
    "        print(f\"acc: {round(get_accuracy().item(), 4)}, loss: {round(calc_loss().item(), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7b270c80-b475-4b12-b19e-33064912c002",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss():\n",
    "    with torch.no_grad():\n",
    "        return torch.as_tensor([mnist_loss(linNet(xb).sigmoid_(), yb) for xb, yb in dset]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "27c39115-9986-484d-be1d-80527b41b9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc: 0.55, loss: 0.4154\n",
      "acc: 0.7738, loss: 0.2103\n",
      "acc: 0.8945, loss: 0.1075\n",
      "acc: 0.9264, loss: 0.0759\n",
      "acc: 0.9401, loss: 0.0614\n",
      "acc: 0.947, loss: 0.0526\n",
      "acc: 0.9524, loss: 0.0467\n",
      "acc: 0.9588, loss: 0.0425\n",
      "acc: 0.9617, loss: 0.0393\n",
      "acc: 0.9652, loss: 0.0369\n"
     ]
    }
   ],
   "source": [
    "run_n_epochs(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3f4da1aa-38ec-43b3-a7aa-3afd2c395a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([14.8719], grad_fn=<AddBackward0>),\n",
       " tensor([1]),\n",
       " tensor(-13.8719, grad_fn=<MeanBackward0>))"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Figuring out why the loss is negative...\n",
    "\n",
    "pred = linNet(valid_dset[0][0])\n",
    "tar = valid_dset[0][1]\n",
    "pred, tar, mnist_loss(pred, tar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bc8a57-372d-4c46-a066-44ef9634fc29",
   "metadata": {},
   "source": [
    "### Done!\n",
    "\n",
    "The calc_loss function was returning a negative, because I was only getting the sigmoid during the actual training, not during the loss or accuracy checks. I think that's the only major thing I missed here.\n",
    "\n",
    "Good session!\n",
    "\n",
    "Next time: Working out the last bit -- using a Learner and Pytorch built-in nets."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
